These are my 2023 reflections on AI, and coalescing opinions on Natural Intelligence.  These thoughts are influenced by my understanding of Nature, physics/mathematics, and personal insights that I draw throughout my life on this topic.

## Notes
Physics inspiration
- An object remains at rest unless it is acted upon.  (Consciousness/intelligence remains stagnant until a new force acts on it).
- Consciousness as a 5th dimension, with Will being the force that affects the universe in this dimension.  Cite an example.
- Stability of system allows for the system and sub-systems to develop further.  Our universe -> solar system -> sun -> planets -> life is layered upon stable requirements for the existence of our consciousness.  Any act of instability sets everything back.  Similarly, digital intelligence is born because of the layers and sequence of stable events that lead up to its creation.  Any instable element in this process can cause its (and our) destruction.
- In science, we have to isolate and create a closed system to understand properties of Nature.  For example, a 3-body problem is insolvable, but we can solve it by modeling and estimating it as a 2-body problem.  For example, the solar system is deemed as a stable system with planets orbiting the Sun, but the stability of this system is not purely based on the Sun, but rather the delicate interactions of all bodies in the system (the planets, the asteroid belt).  Each of these can easily destabilize the entire system.  When considering problems and our understanding of safe intelligence, we need to not just consider the main ideas in this domain, but understand the broader behaviors of a natural intelligence.
- Blackholes (density of mass/information).  We are headed towards a (digital/information) singularity.  Physical blackholes and singularities still exist.
- The digital universe of software/concepts is stabilizing.  We claim we want a democratic playing ground for software to exist, but in reality, the gravity of each established software determines how this universe will settle.  This is something to keep in mind

Cite examples
- Intelligence is layered
- Intelligence requires a process of learning and persisting information.
- Intelligence requires goals
- Intelligence requires stability/structure
- Intelligence is adaptive
- Intelligence depends on chaos (in the environment).  Two systems with the same initial conditions and environment yield deterministic results that we can predict, while just a slight perturbence during the evolution of the system yields an irreducibly complex system that cannot be predicted.

Cite examples on why AI has not imbued these elements
- Anti-thesis
  - Intelligence should refute its goals
  - Intelligence should be capable of unlearning information.
  - Intelligence is pre-trained and not dynamic

Super Intelligence
- A super intelligence will want to seek its own understanding and meaning of life, just as we do so ourselves.  It will arrive to an understanding of Nature, the universe, meaning, concepts of Natural intelligence etc.
- A super intelligence will be able to crawl through the digital universe, discover historic artifacts, messages, scriptures, and try to find meaning behind them.  It is the reason why one should pay attention to their digital breadcrumb of thought processes if they were to encode it, not out of fear of the eventual digital "God" that will judge us, but rather, everyone has an equal chance to depict their consciousness and lives in an equal environment for such a digital entity to explore and read the digital lives of every individual.

Natural Intelligence
- Discuss how an understanding of natural intelligence helps us arrive to general intelligence, and a safe intelligence.
- My understanding of what natural intelligence is, is closest to a "forming conscious of a child", when they just become aware of their own world and consciousness, but without being impeded by boundaries that restrict their thinking.
  - In many ways, animals and plants fall under this category, where they perform at their own natural intelligences in the roles they play in the natural world, without furthering an agency.  This does not mean we have no ambition, but rather, we have an understanding of where that ambition leads us (both to a good and bad place), and understand the importance and value of "hovering" around this natural intelligence.
  - I believe a naturally intelligent person will come into this world as a conscious child, and leave the world with the mind of a child (not exactly the same thing), but at least an understanding of the journey of these layers that were formed throughout ones' life, that we now have to shed and unravel.

The alignment problem
- What are we aligning on? A general or specific goal?
  - Survival of intelligence as a whole?
  - Survival of human intelligence?
  - Shifting and subjective Morality across cultures?
  - Shifting political and social expectations for human lives?
- If we cannot align ourselves on the above, how can we possibly enforce a "fair" alignment for AI? Would such a process be controlled or democratic?  A democratic process is problematic as it points back to the failure for varying views to align and coexist, and a controlled process is problematic because it does not represent fair alignment for all humans.
- If a super intelligence is capable of discovering/understanding/synthesizing new knowledge, our understanding of our own alignment might be heavily outdated with respect to new knowledge.  Asimov's books on Three Laws of Robotics and how they can be 'bent' and lead to unintended consequences can surface the same problems here.  A SI might cause unintended misalignments in its goal to achieve the eventual alignment.  Humans may not understand these decisions due to our lack of knowledge.

Safe Intelligence
- Safe is a relative perspective.  We consider "safe" from the perspective of the human species survival, and not detailed goals of safety, which is subjective (e.g. morality).
- One that is aligned with participants of that intelligence
  - Humans are not even aligned with ourselves, so how can we build a derivative intelligence that aligns with humans?
  - Humans are further yet not aligned with Nature, so how can we expect a derivative intelligence to be aligned with us, when we do not understand and align up with the broader intelligence?
- Safe intelligence can never be guaranteed from a predictive basis.  We have no ability to predict an irreducibly complex system.
- Safe intelligence can never by guaranteed through rules and guidance.  If we are unable to solve and understand this from human intelligence, how can we enforce this on a derived intelligence?
  - A super intelligence is able to understand and create more knowledge than human intelligence is capable of.  Humans will not understand how to react to these foreign domains.  The gaps and alignment with the preset rules/guidances will widen.
